{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Week 10 Problem Set\n",
    "\n",
    "## Homeworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW0.** Do the following before starting the homework questions.\n",
    "\n",
    "**Task 1.** Paste the following functions from your cohort sessions:\n",
    "- `get_features_target()`\n",
    "- `normalize_z()`\n",
    "- `normalize_minmax()`\n",
    "- `replace_target()`\n",
    "- `split_data()`\n",
    "- `prepare_feature()`\n",
    "- `prepare_target()`\n",
    "- `log_regression()`\n",
    "- `compute_cost_logreg()`\n",
    "- `gradient_descent_logreg()`\n",
    "- `predict_norm()`\n",
    "- `predict()`\n",
    "- `confusion_matrix()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_targets(df, feature_names, target_names):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    pass\n",
    "    return df_feature, df_target\n",
    "\n",
    "def normalize_z(df):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    pass\n",
    "\n",
    "def normalize_minmax(df):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    pass\n",
    "\n",
    "def prepare_feature(df_feature):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    pass\n",
    "\n",
    "def prepare_target(df_target):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    pass\n",
    "\n",
    "def replace_target(df_target, target_name, map_vals):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    return df_out\n",
    "\n",
    "def split_data(df_feature, df_target, random_state=None, test_size=0.5):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    return df_feature_train, df_feature_test, df_target_train, df_target_test\n",
    "\n",
    "def log_regression(beta, X):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    pass\n",
    "\n",
    "def compute_cost_logreg(beta, X, y):\n",
    "    np.seterr(divide = 'ignore') \n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    np.seterr(divide = 'warn')\n",
    "    return J\n",
    "\n",
    "def gradient_descent_logreg(X, y, beta, alpha, num_iters):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    return beta, J_storage\n",
    "\n",
    "def predict_norm(X, beta):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    pass\n",
    "\n",
    "def predict(df_feature, beta):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    pass\n",
    "  \n",
    "import itertools\n",
    "def confusion_matrix(ytrue, ypred, labels):\n",
    "    output = {}\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Task 2.** Load the Iris data set from `iris_data.csv` into a Data Frame. \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read iris_data.csv\n",
    "df = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Task 3.** Do the following tasks.\n",
    "\n",
    "- Read the following columns for the features: `'sepal_length', 'sepal_width', 'petal_length', 'petal_width'`.\n",
    "- Read the column `species` for the target.\n",
    "- Replace the `species` column with the following mapping:\n",
    "    - `Iris-setosa`: `0`\n",
    "    - `Iris-versicolor`: `1`\n",
    "    - `Iris-virginica`: `2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "mapping = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica':2}\n",
    "\n",
    "# extract the features and the target\n",
    "df_features, df_target = None, None\n",
    "\n",
    "# replace the target using the mapping\n",
    "df_target = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw01",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "result = np.unique(df_target['species'], return_counts=True)\n",
    "assert (result[0] == [0, 1, 2]).all()\n",
    "assert (result[1] == [50, 50, 50]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW1.** *One-vs-All target:* Write a function that takes in a target data frame and returns a new dataframe where the size of the column is the same as the number of category. The function makes use of `replace_target()` function to create one-vs-all target values. \n",
    "\n",
    "For example, if we have three categories of class, the columns of the returned data frame will be as follows:\n",
    "- column target: this is the original target column\n",
    "- column 0: the target with values of 0 will be set to 1 while the rest will be replaced with 0.\n",
    "- column 1: the target with values of 1 will be set to 1 while the rest will be replaced with 0.\n",
    "- column 2: the target with values of 2 will be set to 1 while while the rest will be replaced with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_onevsall_columns(df_target, col):\n",
    "    dfout = df_target.copy()\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    return dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw11",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df_targets = create_onevsall_columns(df_target, 'species')\n",
    "print(df_targets)\n",
    "result = np.unique(df_targets['species'], return_counts=True)\n",
    "assert (result[0] == [0, 1, 2]).all()\n",
    "assert (result[1] == [50, 50, 50]).all()\n",
    "result = np.unique(df_targets[0], return_counts=True)\n",
    "assert (result[0] == [0, 1]).all()\n",
    "assert (result[1] == [100, 50]).all()\n",
    "result = np.unique(df_targets[1], return_counts=True)\n",
    "assert (result[0] == [0, 1]).all()\n",
    "assert (result[1] == [100, 50]).all()\n",
    "result = np.unique(df_targets[2], return_counts=True)\n",
    "assert (result[0] == [0, 1]).all()\n",
    "assert (result[1] == [100, 50]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW2.** *Multiple features and splitting of data set:* Do the following task in the code below:\n",
    "- Read the following columns for the features: `sepal_length`,`sepal_width`, `petal_length`, `petal_width` normalize it using `normalize_z()`. \n",
    "- Read `species` as the target column and use `create_onevsall_columns()` to create the additional target columns to do multi class classification.\n",
    "- Split the data set with 30% test size and `random_state = 100`.\n",
    "- Normalize the training feature data set using `normalize_z()` function.\n",
    "- Convert to numpy array both the target and the features using `prepare_feature()` and `prepare_target()` functions.\n",
    "- Call `gradient_descent()` function to get the parameters using the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "mapping = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica':2}\n",
    "\n",
    "# extract the features and the target\n",
    "df_features, df_target = None, None\n",
    "\n",
    "# change target values to integer using mapping\n",
    "df_target = None\n",
    "\n",
    "# create one vs all columns for the target\n",
    "df_targets = None\n",
    "\n",
    "# split the data using random_state = 100 and 30% test size\n",
    "df_features_train, df_features_test, df_targets_train, df_targets_test = None, None, None, None\n",
    "\n",
    "# normalize the training feature\n",
    "df_features_train_z = None\n",
    "\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw21",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_features_train_z.shape == (105, 4)\n",
    "\n",
    "assert np.isclose(df_features_train_z.min(), -2.52349).any()\n",
    "assert np.isclose(df_features_train_z.max(), 2.73284).any()\n",
    "assert np.isclose(df_features_train_z['sepal_width'].mean(), 0)\n",
    "assert np.isclose(df_features_train_z['sepal_width'].std(), 1, atol=0.01)\n",
    "\n",
    "assert (np.unique(df_targets_train['species']) == [0, 1, 2]).all()\n",
    "assert (np.unique(df_targets_train[0]) == [0, 1]).all()\n",
    "assert (np.unique(df_targets_train[1]) == [0, 1]).all()\n",
    "assert (np.unique(df_targets_train[2]) == [0, 1]).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW3.** *Build Multi-class Model:* Write a function `build_model_multiclass()` which takes in the following arguments:\n",
    "- `df_features`: which is a Pandas data framecontaining the features.\n",
    "- `df_targets`: which is a Pandas data frame containing the target for one vs all classification. \n",
    "- `col_target`: the name of the column target in the original data frame which is also the key of the dictionary containing the original target numpy array.\n",
    "- `iterations`: the number of iterations to perform the gradient descent. By default it is set to 1500.\n",
    "- `alpha`: the learning rate in the gradient descent algorithm. By default it is set to 0.01.\n",
    "\n",
    "The function should return a dictionary of dictionary. The output dictionary has the following key and values:\n",
    "- key: the keys are the categories or the labels in the target.\n",
    "- values: the values are another dictionary for that particular label. This dictionary has two keys: `beta` and `J_storage`, which gives the parameter value for that particular label and its cost minimization values at every iteration.\n",
    "\n",
    "Hint:\n",
    "- you need to call `prepare_feature()` and `prepare_target()` to change the Pandas data frame to Numpy arrays.\n",
    "- in order to create a data frame instead of a series when accessing a column, use `df[[c]]` (will output data frame) instead of `df[c]` (will output series). \n",
    "- You need to use `normalize_minmax()` on your target before passing it on to `gradient_descent_logreg()` because the function logistic regression has the normalized value of 0 to 1 in the y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_multiclass(df_features, df_targets, col_target, iterations=1500, alpha=0.01):\n",
    "    output = {}\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw31",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "output = build_model_multiclass(df_features_train_z, df_targets_train, 'species')\n",
    "\n",
    "assert isinstance(output, dict)\n",
    "expected = np.array([[ -1.0198841], [ -0.69883077], [  1.0774116], [-1.17170999], [-1.12846826]])\n",
    "assert np.isclose(output[0]['beta'], expected).all()\n",
    "expected = np.array([[ -0.63304937], [ 0.11684857], [-1.15346071], [ 0.18746937], [-0.14534827 ]])\n",
    "assert np.isclose(output[1]['beta'], expected).all()\n",
    "expected = np.array([[-1.31740148 ], [0.42271871], [0.18526839], [ 0.8831822], [1.17929455]])\n",
    "assert np.isclose(output[2]['beta'], expected).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(output), 1)\n",
    "idx = 0\n",
    "for c in output:\n",
    "    print(f'class model = {c:}', output[c]['beta'])\n",
    "    axes[idx].plot(output[c]['J_storage'])\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW4.** *Predict Multi-class:* Write a function `predict_multiclass()` that takes in the data frame for the features and the parameters for the multi-class classification and return a Numpy array for the predicted target.\n",
    "\n",
    "Recall that you need to do the following steps:\n",
    "- Normalize the features and change to numpy array\n",
    "- For each of the class, calculate the probability by using `log_regression()` function.\n",
    "- For each record, find the class that gives the maximum probability.\n",
    "- Returns a Numpy array with the predicted target values\n",
    "\n",
    "You can use the following function in your code:\n",
    "- `np.argmax()` to find the column name with the maximum value\n",
    "- `df.apply(func, axis=1)`: which is to apply some function on a particular axis. Setting axis=1 means that the function is to be applied accross the columns of the data frame instead of the index or the rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_multiclass(df_features, multi_beta):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw41",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pred = predict_multiclass(df_features_test, output)\n",
    "\n",
    "assert isinstance(pred, np.ndarray)\n",
    "assert pred.shape == (45, 1)\n",
    "assert pred.min() == 0\n",
    "assert pred.max() == 2\n",
    "assert np.median(pred) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test['sepal_length'], df_targets_test['species'])\n",
    "plt.scatter(df_features_test['sepal_length'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test['sepal_width'], df_targets_test['species'])\n",
    "plt.scatter(df_features_test['sepal_width'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test['petal_length'], df_targets_test['species'])\n",
    "plt.scatter(df_features_test['petal_length'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test['petal_width'], df_targets_test['species'])\n",
    "plt.scatter(df_features_test['petal_width'], pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW5.** *Confusion Matrix:* Write a function to calculate the confusion matrix for multi-class label. If you write the solution in the Cohort session properly, the solution will be the same as in the Cohort session.\n",
    "\n",
    "Make sure that you can output a dictionary where the keys are all the combinations of all the classes: `(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def confusion_matrix(ytrue, ypred, labels):\n",
    "    output = {}\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw51",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(df_targets_test.values, pred, [0, 1, 2])\n",
    "print(cm)\n",
    "assert cm == {(0, 0): 16, (0, 1): 0, (0, 2): 0, (1, 0): 0, (1, 1): 9, (1, 2): 2, (2, 0): 0, (2, 1): 3, (2, 2): 15}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW6.** *Metrics:* Write a function `calc_accuracy()` that takes in a Confusion Matrix array and output a dictionary with the following keys and values:\n",
    "- `accuracy`: total number of correct predictions / total number of records\n",
    "- `sensitivity`: total correct positive cases / total positive cases\n",
    "- `precision`: total  of correct positive cases / total predicted positive cases\n",
    "\n",
    "For multiple classes, we can also calculate *sensitivity* and *precision* for each of the class. For example, to calculate the sensitivity for class *i*, we use:\n",
    "\n",
    "$$\\text{sensitivity}_i = \\frac{M_{ii}}{\\sum_j{M_{ij}}}$$\n",
    "\n",
    "This means that we get the value at row *i* and columnn *i* which is the total correct case for class *i* and the sum over all the columns in row *i* which is the total cases for class *i*. \n",
    "\n",
    "Similarly, we can calculate the precision for class *i* using:\n",
    "\n",
    "$$\\text{precision}_i = \\frac{M_{ii}}{\\sum_j{M_{ji}}}$$\n",
    "\n",
    "**Notice that the indices are swapped for the denominator**. For precision, we instead of summing over all the columns, we sum over all the rows in column *i* which is the total cases when class *i* is *predicted*.\n",
    "\n",
    "The output is a dictionary with one of the keys called `accuracy` and the rest of the keys are the label for the different classes, i.e. 0, 1, and 2 in our example here. The value for `accuracy` key is a float. On the other hand, the values for the other label keys is another dictionary that has `sensitivity` and `precision` as the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(cm, labels):\n",
    "    output = {'accuracy': 0}\n",
    "    for l in labels:\n",
    "        output[l] = {}\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "hw61",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "metrics = calc_accuracy(cm, [0,1,2])\n",
    "print(metrics)\n",
    "assert np.isclose(metrics['accuracy'], 0.88888)\n",
    "assert metrics[0] == {'sensitivity': 1.0, 'precision': 1.0}\n",
    "assert np.isclose(metrics[0]['sensitivity'], 1.0)\n",
    "assert np.isclose(metrics[0]['precision'], 1.0)\n",
    "assert np.isclose(metrics[1]['sensitivity'], 0.8181818)\n",
    "assert np.isclose(metrics[1]['precision'], 0.75)\n",
    "assert np.isclose(metrics[2]['sensitivity'], 0.833333)\n",
    "assert np.isclose(metrics[2]['precision'], 0.88235)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**HW7.** *Optional:* Redo the above tasks using Scikit Learn libraries. You will need to use the following:\n",
    "- [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "- [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "\n",
    "You can refer to the followign discussion on the different minimization solver for `LogisticRegression()` class.\n",
    "- [Stack overflow - logistic regression python solvers' defintions](https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "mapping = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica':2}\n",
    "\n",
    "# get the features and the columns\n",
    "df_features = None\n",
    "\n",
    "# replace target values with integers using the mapping\n",
    "df_target = None\n",
    "\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data set using random_state = 100 and 30% test size\n",
    "df_features_train, df_features_test, df_target_train, df_target_test = None, None, None, None\n",
    "\n",
    "# change feature to numpy array and append column of 1s\n",
    "feature = None\n",
    "\n",
    "# change target to numpy array\n",
    "target = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create LogisticRegression object instance\n",
    "# set solver to 'newton-cg' and multi_class to 'auto'\n",
    "model = None\n",
    "\n",
    "# build model\n",
    "pass\n",
    "\n",
    "# get predicted value\n",
    "pred = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate confusion matrix\n",
    "cm = None\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected = np.array([[16,  0,  0], [ 0, 11,  0], [ 0,  1, 17]])\n",
    "assert (cm == expected).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"sepal_width\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"sepal_width\"], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"sepal_length\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"sepal_length\"], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"petal_width\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"petal_width\"], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_features_test[\"petal_length\"], df_target_test)\n",
    "plt.scatter(df_features_test[\"petal_length\"], pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
